{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DeJx7tguCjnb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, PredictionErrorDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from tabulate import tabulate\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Categorical, Integer, Continuous\n",
    "\n",
    "path = 'SAMPLE_DATA_SET.xlsx'\n",
    "\n",
    "# Read and load dataset\n",
    "df= pd.read_excel(path, sheet_name=[0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LoGSDzBCkPR"
   },
   "source": [
    "INPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1714748289388,
     "user": {
      "displayName": "Giovanni Lombardo",
      "userId": "17752443154386048654"
     },
     "user_tz": -120
    },
    "id": "JJcSpwV0CmiK",
    "outputId": "f0820786-ee5f-4976-8605-6fe7d498a257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 444)\n"
     ]
    }
   ],
   "source": [
    "X =df.get(0)\n",
    "X = (X.iloc[:,1:]).values\n",
    "X = X.T\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wMhRqrsCojw"
   },
   "source": [
    "OUTPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1714748289388,
     "user": {
      "displayName": "Giovanni Lombardo",
      "userId": "17752443154386048654"
     },
     "user_tz": -120
    },
    "id": "QDo7dWOmCrT9",
    "outputId": "0ca1733b-ea5c-459f-b4c6-ecfda32aa195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 2)\n"
     ]
    }
   ],
   "source": [
    "Y =df.get(1)\n",
    "Y = (Y.iloc[:,:]).values\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlPjOdAQKgqr"
   },
   "source": [
    "RIDGE REGRESSION with closed form solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nl-BG2_fKmCA"
   },
   "outputs": [],
   "source": [
    "a1 = 0.01\n",
    "a2 = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "executionInfo": {
     "elapsed": 4185248,
     "status": "error",
     "timestamp": 1714752830985,
     "user": {
      "displayName": "Giovanni Lombardo",
      "userId": "17752443154386048654"
     },
     "user_tz": -120
    },
    "id": "Y7HQm0eyKWEH",
    "outputId": "5384448a-0c74-4df3-b631-402f97ec8602"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovanni/.local/lib/python3.10/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/giovanni/.local/lib/python3.10/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tfitness\tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t10    \t-2.0755\t0.0418157  \t-2.05335   \t-2.19696   \n",
      "1  \t20    \t-2.05341\t8.46817e-05\t-2.05335   \t-2.05363   \n",
      "2  \t20    \t-2.05361\t0.0005051  \t-2.05335   \t-2.05462   \n",
      "3  \t20    \t-2.05336\t1.15805e-06\t-2.05336   \t-2.05336   \n",
      "4  \t20    \t-2.05376\t0.000837317\t-2.05336   \t-2.05602   \n",
      "5  \t20    \t-2.05381\t0.000530987\t-2.05336   \t-2.05459   \n",
      "6  \t20    \t-2.05407\t0.00152975 \t-2.05336   \t-2.05862   \n",
      "7  \t20    \t-2.05439\t0.00195438 \t-2.05336   \t-2.05862   \n",
      "8  \t20    \t-2.05344\t8.06566e-05\t-2.05335   \t-2.05352   \n",
      "9  \t20    \t-2.05342\t7.46397e-05\t-2.05335   \t-2.05355   \n",
      "10 \t20    \t-2.05341\t7.586e-05  \t-2.05335   \t-2.05359   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovanni/.local/lib/python3.10/site-packages/sklearn_genetic/genetic_search.py:279: UserWarning: Warning, only one parameter was provided to the param_grid, the optimization routine might not have effect or it could lead to errors, it's advised to use at least 2 parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t10    \t-1.96982\t0.0230355  \t-1.95932   \t-2.03863   \n",
      "1  \t20    \t-1.96052\t0.0012619  \t-1.95932   \t-1.96313   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7cc0adf1c310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: Fatal Python error: init_import_site: Failed to import the site module\n",
      "Python runtime state: initialized\n",
      "<function _releaseLock at 0x7cc0adf1c310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/site.py\", line 636, in <module>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/home/giovanni/.local/lib/python3.10/site-packages/joblib/__init__.py\", line 114, in <module>\n",
      "    main()\n",
      "  File \"/usr/lib/python3.10/site.py\", line 622, in main\n",
      "    __import__(pkg_name)\n",
      "  File \"/home/giovanni/.local/lib/python3.10/site-packages/joblib/__init__.py\", line 114, in <module>\n",
      "    from .memory import Memory\n",
      "  File \"/home/giovanni/.local/lib/python3.10/site-packages/joblib/memory.py\", line 12, in <module>\n",
      "    import asyncio\n",
      "  File \"/usr/lib/python3.10/asyncio/__init__.py\", line 8, in <module>\n",
      "    from .base_events import *\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 23, in <module>\n",
      "    known_paths = addusersitepackages(known_paths)\n",
      "  File \"/usr/lib/python3.10/site.py\", line 349, in addusersitepackages\n",
      "    import socket\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 85, in <module>\n",
      "    from .memory import Memory\n",
      "  File \"/home/giovanni/.local/lib/python3.10/site-packages/joblib/memory.py\", line 12, in <module>\n",
      "    import asyncio\n",
      "  File \"/usr/lib/python3.10/asyncio/__init__.py\", line 8, in <module>\n",
      "    from .base_events import *\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 18, in <module>\n",
      "    addsitedir(user_site, known_paths)\n",
      "  File \"/usr/lib/python3.10/site.py\", line 232, in addsitedir\n",
      "    import concurrent.futures\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/__init__.py\", line 8, in <module>\n",
      "    from concurrent.futures._base import (FIRST_COMPLETED,\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 7, in <module>\n",
      "    IntFlag._convert_(\n",
      "  File \"/usr/lib/python3.10/enum.py\", line 553, in _convert_\n",
      "    import logging\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 26, in <module>\n",
      "    addpackage(sitedir, name, known_paths)\n",
      "  File \"/usr/lib/python3.10/site.py\", line 192, in addpackage\n",
      "    import sys, os, time, io, re, traceback, warnings, weakref, collections.abc\n",
      "  File \"/usr/lib/python3.10/re.py\", line 125, in <module>\n",
      "    members = [\n",
      "    exec(line)\n",
      "  File \"/usr/lib/python3.10/enum.py\", line 556, in <listcomp>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 674, in _load_unlocked\n",
      "    if filter(name)]\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 88, in <lambda>\n",
      "  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\n",
      "    import sre_compile\n",
      "  File \"/usr/lib/python3.10/sre_compile.py\", line 14, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 556, in _init_module_attrs\n",
      "    lambda C: C.isupper() and C.startswith('MSG_'))\n",
      "  File \"<frozen importlib._bootstrap>\", line 397, in cached\n",
      "KeyboardInterrupt\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 513, in _get_cached\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 406, in cache_from_source\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 134, in _path_split\n",
      "KeyboardInterrupt\n",
      "    import sre_parse\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 15, in <module>\n",
      "    from sre_constants import *\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGINT(-2), SIGINT(-2), EXIT(1), SIGINT(-2)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 35\u001b[0m\n\u001b[1;32m     24\u001b[0m ridge_reg_cl \u001b[38;5;241m=\u001b[39m Ridge(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcholesky\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m evolved_estimator \u001b[38;5;241m=\u001b[39m GASearchCV(estimator\u001b[38;5;241m=\u001b[39mridge_reg_cl,\n\u001b[1;32m     27\u001b[0m                       cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     28\u001b[0m                       scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m                       population_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     33\u001b[0m                       generations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mevolved_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Make predictions using the testing set\u001b[39;00m\n\u001b[1;32m     38\u001b[0m Y_pred_ridge_cl \u001b[38;5;241m=\u001b[39m  evolved_estimator\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn_genetic/genetic_search.py:492\u001b[0m, in \u001b[0;36mGASearchCV.fit\u001b[0;34m(self, X, y, callbacks)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register()\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# Optimization routine from the selected evolutionary algorithm\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m pop, log, n_gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hof\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# Update the _n_iterations value as the algorithm could stop earlier due a callback\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_iterations \u001b[38;5;241m=\u001b[39m n_gen\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn_genetic/genetic_search.py:572\u001b[0m, in \u001b[0;36mGASearchCV._select_algorithm\u001b[0;34m(self, pop, stats, hof)\u001b[0m\n\u001b[1;32m    570\u001b[0m selected_algorithm \u001b[38;5;241m=\u001b[39m algorithms_factory\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_algorithm:\n\u001b[0;32m--> 572\u001b[0m     pop, log, gen \u001b[38;5;241m=\u001b[39m \u001b[43mselected_algorithm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoolbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulation_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulation_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcxpb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrossover_adapter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutpb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutation_adapter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mngen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhalloffame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe algorithm \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease select one from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAlgorithms\u001b[38;5;241m.\u001b[39mlist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    591\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn_genetic/algorithms.py:327\u001b[0m, in \u001b[0;36meaMuPlusLambda\u001b[0;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, stats, halloffame, callbacks, verbose, estimator, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m invalid_ind \u001b[38;5;241m=\u001b[39m [ind \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m offspring \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ind\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalid]\n\u001b[1;32m    326\u001b[0m fitnesses \u001b[38;5;241m=\u001b[39m toolbox\u001b[38;5;241m.\u001b[39mmap(toolbox\u001b[38;5;241m.\u001b[39mevaluate, invalid_ind)\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind, fit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(invalid_ind, fitnesses):\n\u001b[1;32m    328\u001b[0m     ind\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m fit\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# Update the hall of fame with the generated individuals\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn_genetic/genetic_search.py:399\u001b[0m, in \u001b[0;36mGASearchCV.evaluate\u001b[0;34m(self, individual)\u001b[0m\n\u001b[1;32m    396\u001b[0m local_estimator\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcurrent_generation_params)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# Compute the cv-metrics\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m cv_results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    412\u001b[0m score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cv_scores)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGINT(-2), SIGINT(-2), EXIT(1), SIGINT(-2)}"
     ]
    }
   ],
   "source": [
    "#number of trials\n",
    "trials = 100\n",
    "np.random.seed(42)\n",
    "seeds = np.random.randint(trials, size=trials)\n",
    "\n",
    "ripartisions = [i/100 for i in range(5,55,5)]\n",
    "results = []  #[\"Ripartition\", \"Best_MSE1\", \"Best_MSE2\",\"MSE1_mean\",\"MSE2_mean\",\"MSE1_var\",\"MSE2_var\",\"alpha1\",\"alpha2\"]\n",
    "\n",
    "\n",
    "for ripartition in ripartisions:\n",
    "\n",
    "    '''PARAM 1'''\n",
    "\n",
    "    MSE_param1 = []\n",
    "\n",
    "    best_MSE_1 = 100000000\n",
    "    best_data_1 = {\"Y_test\":None, \"Y_pred\":None,\"alpha\":None}\n",
    "\n",
    "    i = 0\n",
    "    for i in range(trials):\n",
    "        #Ripartition in training and test and\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:,0], test_size=ripartition, random_state=seeds[i])\n",
    "        param_grid = {'alpha': Continuous(1/100000,0.01)}\n",
    "        ridge_reg_cl = Ridge(solver=\"cholesky\")\n",
    "        \n",
    "        evolved_estimator = GASearchCV(estimator=ridge_reg_cl,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              param_grid=param_grid,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=True,\n",
    "                              population_size=10,\n",
    "                              generations=10)\n",
    "\n",
    "        evolved_estimator.fit(X_train, Y_train)\n",
    "\n",
    "        # Make predictions using the testing set\n",
    "        Y_pred_ridge_cl =  evolved_estimator.predict(X_test)\n",
    "\n",
    "        #save MSE of the first parameters\n",
    "        MSE_param1.append(mean_squared_error(Y_test, Y_pred_ridge_cl))\n",
    "\n",
    "        #check if this is the best model in terms of MSE\n",
    "        if MSE_param1[-1] < best_MSE_1:\n",
    "          best_MSE_1 = MSE_param1[-1]\n",
    "          best_data_1[\"Y_test\"] = Y_test\n",
    "          best_data_1[\"Y_pred\"] = Y_pred_ridge_cl\n",
    "          best_data_1[\"alpha\"] =  float(evolved_estimator.best_params_[\"alpha\"])\n",
    "\n",
    "\n",
    "    '''PARAM 2'''\n",
    "    MSE_param2 = []\n",
    "\n",
    "    best_MSE_2 = 100000000\n",
    "    best_data_2 = {\"Y_test\":None, \"Y_pred\":None,\"alpha\":None}\n",
    "\n",
    "    i = 0\n",
    "    for i in range(trials):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:,1], test_size=ripartition, random_state=seeds[i])\n",
    "        param_grid = param_grid = {'alpha': Continuous(1/100000,0.01)}\n",
    "        ridge_reg_cl = Ridge(solver=\"cholesky\")\n",
    "\n",
    "        evolved_estimator = GASearchCV(estimator=ridge_reg_cl,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              param_grid=param_grid,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=True,\n",
    "                              population_size=10,\n",
    "                              generations=10)\n",
    "\n",
    "        evolved_estimator.fit(X_train, Y_train)\n",
    "\n",
    "        # Make predictions using the testing set\n",
    "        Y_pred_ridge_cl =  evolved_estimator.predict(X_test)\n",
    "        #save MSE of the second parameters\n",
    "        MSE_param2.append(mean_squared_error(Y_test, Y_pred_ridge_cl))\n",
    "\n",
    "        #check if this is the best model in terms of MSE\n",
    "        if MSE_param2[-1] < best_MSE_2:\n",
    "          best_MSE_2 = MSE_param2[-1]\n",
    "          best_data_2[\"Y_test\"] = Y_test\n",
    "          best_data_2[\"Y_pred\"] = Y_pred_ridge_cl\n",
    "          best_data_2[\"alpha\"] =  float(evolved_estimator.best_params_[\"alpha\"])\n",
    "\n",
    "\n",
    "    results.append([str(ripartition *100 ), str(best_MSE_1), str(best_MSE_2),\n",
    "                    (np.mean(MSE_param1)),str(np.mean(MSE_param2)), str(np.var(MSE_param1)),\n",
    "                    str(np.var(MSE_param2)), str(np.var(MSE_param2)), str(best_data_1[\"alpha\"]), str(best_data_2[\"alpha\"])])\n",
    "\n",
    "    '''PLOT THE BEST MODELS'''\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    PredictionErrorDisplay.from_predictions(y_true=best_data_1[\"Y_test\"], y_pred=best_data_1[\"Y_pred\"], kind = \"actual_vs_predicted\", ax=axs[0])\n",
    "    axs[0].set_title(\"Parameter 1\"+\"\\n\"+ \"MSE: \" +  str(min(MSE_param1)) + \"\\n\" + \" alpha= \"+ str(best_data_1[\"alpha\"]))\n",
    "    disp2= PredictionErrorDisplay.from_predictions(y_true=best_data_2[\"Y_test\"], y_pred=best_data_2[\"Y_pred\"], kind = \"actual_vs_predicted\", ax=axs[1])\n",
    "    axs[1].set_title(\"Parameter 2\"+\"\\n\"+ \"MSE: \" +  str(min(MSE_param2)) + \"\\n\" + \" alpha= \"+ str(best_data_2[\"alpha\"]))\n",
    "    fig.suptitle(\"Ridge Regression with closed form\"+\"\\n\"+ \"Best MSE results\" + \"\\n\"+ f\"Test size(%): {ripartition * 100}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "'''SHOW RESULTS'''\n",
    "headers = [\"Test size(%)\",\"Best(MSE1)\", \"Best(MSE2)\",\"Mean(MSE1)\", \"Mean(MSE2)\", \"Var(MSE1)\", \"Var(MSE2)\",\"alpha1\",\"alpha2\"]\n",
    "\n",
    "print(tabulate(results, headers,  tablefmt=\"double_outline\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDlfwPf7Kpmz"
   },
   "source": [
    "**RIDGE REGRESSION with SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3quqTzaKwN6"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "#number of trials\n",
    "trials = 100\n",
    "np.random.seed(42)\n",
    "seeds = np.random.randint(trials, size=trials)\n",
    "\n",
    "ripartisions = [i/100 for i in range(5,55,5)]\n",
    "results = []  #[\"Ripartition\", \"Best_MSE1\", \"Best_MSE2\",\"MSE1_mean\",\"MSE2_mean\",\"MSE1_var\",\"MSE2_var\",\"alpha1\",\"alpha2\"]\n",
    "\n",
    "\n",
    "for ripartition in ripartisions:\n",
    "\n",
    "    '''PARAM 1'''\n",
    "\n",
    "    MSE_param1 = []\n",
    "\n",
    "    best_MSE_1 = 100000000\n",
    "    best_data_1 = {\"Y_test\":None, \"Y_pred\":None,\"alpha\":None}\n",
    "\n",
    "    i = 0\n",
    "    for i in range(trials):\n",
    "        #Ripartition in training and test and\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:,0], test_size=ripartition, random_state=seeds[i])\n",
    "        param_grid = {'alpha': Continuous(1/100000,0.01)}\n",
    "        ridge_reg_sgd = SGDRegressor(max_iter=5000, tol=1e-5, penalty=\"l2\", eta0=0.01,\n",
    "                                            n_iter_no_change=10, random_state=42)\n",
    "\n",
    "        evolved_estimator = GASearchCV(estimator=ridge_reg_cl,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              param_grid=param_grid,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=True,\n",
    "                              population_size=10,\n",
    "                              generations=10)\n",
    "\n",
    "        evolved_estimator.fit(X_train, Y_train)\n",
    "\n",
    "        # Make predictions using the testing set\n",
    "        Y_pred_ridge_sgd =  evolved_estimator.predict(X_test)\n",
    "\n",
    "        #save MSE of the first parameters\n",
    "        MSE_param1.append(mean_squared_error(Y_test, Y_pred_ridge_sgd))\n",
    "\n",
    "        #check if this is the best model in terms of MSE\n",
    "        if MSE_param1[-1] < best_MSE_1:\n",
    "          best_MSE_1 = MSE_param1[-1]\n",
    "          best_data_1[\"Y_test\"] = Y_test\n",
    "          best_data_1[\"Y_pred\"] = Y_pred_ridge_sgd\n",
    "          best_data_1[\"alpha\"] =  float(evolved_estimator.best_params_[\"alpha\"])\n",
    "\n",
    "\n",
    "    '''PARAM 2'''\n",
    "    MSE_param2 = []\n",
    "\n",
    "    best_MSE_2 = 100000000\n",
    "    best_data_2 = {\"Y_test\":None, \"Y_pred\":None,\"alpha\":None}\n",
    "\n",
    "    i = 0\n",
    "    for i in range(trials):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:,1], test_size=ripartition, random_state=seeds[i])\n",
    "        param_grid = {'alpha': Continuous(1/100000,0.01)}\n",
    "        ridge_reg_sgd = SGDRegressor(max_iter=5000, tol=1e-5, penalty=\"l2\", eta0=0.01,\n",
    "                                            n_iter_no_change=10, random_state=42)\n",
    "\n",
    "        evolved_estimator = GASearchCV(estimator=ridge_reg_cl,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              param_grid=param_grid,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=True,\n",
    "                              population_size=10,\n",
    "                              generations=10)\n",
    "\n",
    "        evolved_estimator.fit(X_train, Y_train)\n",
    "\n",
    "        # Make predictions using the testing set\n",
    "        Y_pred_ridge_sgd =  evolved_estimator.predict(X_test)\n",
    "\n",
    "        #save MSE of the second parameters\n",
    "        MSE_param2.append(mean_squared_error(Y_test, Y_pred_ridge_sgd))\n",
    "\n",
    "        #check if this is the best model in terms of MSE\n",
    "        if MSE_param2[-1] < best_MSE_2:\n",
    "          best_MSE_2 = MSE_param2[-1]\n",
    "          best_data_2[\"Y_test\"] = Y_test\n",
    "          best_data_2[\"Y_pred\"] = Y_pred_ridge_sgd\n",
    "          best_data_2[\"alpha\"] =  float(evolved_estimator.best_params_[\"alpha\"])\n",
    "\n",
    "    results.append([str(ripartition *100 ), str(best_MSE_1), str(best_MSE_2),\n",
    "     (np.mean(MSE_param1)),str(np.mean(MSE_param2)), str(np.var(MSE_param1)), str(np.var(MSE_param2)),str(best_data_1[\"alpha\"]),str(best_data_2[\"alpha\"])])\n",
    "\n",
    "    '''PLOT THE BEST MODELS'''\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    PredictionErrorDisplay.from_predictions(y_true=best_data_1[\"Y_test\"], y_pred=best_data_1[\"Y_pred\"], kind = \"actual_vs_predicted\", ax=axs[0])\n",
    "    axs[0].set_title(\"Parameter 1\"+\"\\n\"+ \"MSE: \" +  str(min(MSE_param1)) + \"\\n\" + \" alpha= \"+ str(best_data_1[\"alpha\"]))\n",
    "    disp2= PredictionErrorDisplay.from_predictions(y_true=best_data_2[\"Y_test\"], y_pred=best_data_2[\"Y_pred\"], kind = \"actual_vs_predicted\", ax=axs[1])\n",
    "    axs[1].set_title(\"Parameter 2\"+\"\\n\"+ \"MSE: \" +  str(min(MSE_param2)) + \"\\n\" + \" alpha= \"+ str(best_data_2[\"alpha\"]))\n",
    "    fig.suptitle(\"Ridge Regression with SGD\"+\"\\n\"+ \"Best MSE results\" + \"\\n\"+ f\"Test size(%): {ripartition * 100}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "'''SHOW RESULTS'''\n",
    "headers = [\"Test size(%)\",\"Best(MSE1)\", \"Best(MSE2)\",\"Mean(MSE1)\", \"Mean(MSE2)\", \"Var(MSE1)\", \"Var(MSE2)\",\"alpha1\",\"alpha2\"]\n",
    "\n",
    "print(tabulate(results, headers,  tablefmt=\"double_outline\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNhfNv01AdXHvYyGO9QKrtm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
