{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jZANRSc1ss80"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, PredictionErrorDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tabulate import tabulate\n",
    "from sklearn.linear_model import Lasso\n",
    "import mlflow\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Categorical, Integer, Continuous\n",
    "path = 'SAMPLE_DATA_SET.xlsx'\n",
    "\n",
    "# Read and load dataset\n",
    "df= pd.read_excel(path, sheet_name=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hE6UIW-gstdL"
   },
   "source": [
    "INPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZF1iKaZ1svcD",
    "outputId": "ce6e2d6f-05e3-446c-cdbf-8b5a76abae4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 444)\n"
     ]
    }
   ],
   "source": [
    "X =df.get(0)\n",
    "X = (X.iloc[:,1:]).values\n",
    "X = X.T\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN-jNRWosxRY"
   },
   "source": [
    "OUTPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QjKQP0HVsyzg",
    "outputId": "97a34522-8990-4bd9-8f7c-91eeb7a79587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 2)\n"
     ]
    }
   ],
   "source": [
    "Y =df.get(1)\n",
    "Y = (Y.iloc[:,:]).values\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEmshJfCK8Bz"
   },
   "source": [
    "**LASSO with coordinate descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "veRVY9X5LE5_",
    "outputId": "bec6375e-5aff-4dbe-83e2-b26941aee12a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param 1\n",
      "Ripartion: 0.05 - trial: 0\n",
      "Ripartion: 0.05 - trial: 1\n",
      "Ripartion: 0.05 - trial: 2\n",
      "Ripartion: 0.05 - trial: 3\n",
      "Ripartion: 0.05 - trial: 4\n",
      "Ripartion: 0.05 - trial: 5\n",
      "Ripartion: 0.05 - trial: 6\n",
      "Ripartion: 0.05 - trial: 7\n",
      "Ripartion: 0.05 - trial: 8\n",
      "Ripartion: 0.05 - trial: 9\n",
      "Ripartion: 0.05 - trial: 10\n",
      "Ripartion: 0.05 - trial: 11\n",
      "Ripartion: 0.05 - trial: 12\n",
      "Ripartion: 0.05 - trial: 13\n",
      "Ripartion: 0.05 - trial: 14\n",
      "Ripartion: 0.05 - trial: 15\n",
      "Ripartion: 0.05 - trial: 16\n",
      "Ripartion: 0.05 - trial: 17\n",
      "Ripartion: 0.05 - trial: 18\n",
      "Ripartion: 0.05 - trial: 19\n",
      "Ripartion: 0.05 - trial: 20\n",
      "Ripartion: 0.05 - trial: 21\n",
      "Ripartion: 0.05 - trial: 22\n",
      "Ripartion: 0.05 - trial: 23\n",
      "Ripartion: 0.05 - trial: 24\n",
      "Ripartion: 0.05 - trial: 25\n",
      "Ripartion: 0.05 - trial: 26\n",
      "Ripartion: 0.05 - trial: 27\n",
      "Ripartion: 0.05 - trial: 28\n",
      "Ripartion: 0.05 - trial: 29\n",
      "Ripartion: 0.05 - trial: 30\n",
      "Ripartion: 0.05 - trial: 31\n",
      "Ripartion: 0.05 - trial: 32\n",
      "Ripartion: 0.05 - trial: 33\n",
      "Ripartion: 0.05 - trial: 34\n",
      "Ripartion: 0.05 - trial: 35\n",
      "Ripartion: 0.05 - trial: 36\n",
      "Ripartion: 0.05 - trial: 37\n",
      "Ripartion: 0.05 - trial: 38\n",
      "Ripartion: 0.05 - trial: 39\n",
      "Ripartion: 0.05 - trial: 40\n",
      "Ripartion: 0.05 - trial: 41\n",
      "Ripartion: 0.05 - trial: 42\n",
      "Ripartion: 0.05 - trial: 43\n",
      "Ripartion: 0.05 - trial: 44\n",
      "Ripartion: 0.05 - trial: 45\n",
      "Ripartion: 0.05 - trial: 46\n",
      "Ripartion: 0.05 - trial: 47\n",
      "Ripartion: 0.05 - trial: 48\n",
      "Ripartion: 0.05 - trial: 49\n",
      "Ripartion: 0.05 - trial: 50\n",
      "Ripartion: 0.05 - trial: 51\n",
      "Ripartion: 0.05 - trial: 52\n",
      "Ripartion: 0.05 - trial: 53\n",
      "Ripartion: 0.05 - trial: 54\n",
      "Ripartion: 0.05 - trial: 55\n",
      "Ripartion: 0.05 - trial: 56\n",
      "Ripartion: 0.05 - trial: 57\n",
      "Ripartion: 0.05 - trial: 58\n",
      "Ripartion: 0.05 - trial: 59\n",
      "Ripartion: 0.05 - trial: 60\n",
      "Ripartion: 0.05 - trial: 61\n",
      "Ripartion: 0.05 - trial: 62\n",
      "Ripartion: 0.05 - trial: 63\n",
      "Ripartion: 0.05 - trial: 64\n",
      "Ripartion: 0.05 - trial: 65\n",
      "Ripartion: 0.05 - trial: 66\n",
      "Ripartion: 0.05 - trial: 67\n",
      "Ripartion: 0.05 - trial: 68\n",
      "Ripartion: 0.05 - trial: 69\n",
      "Ripartion: 0.05 - trial: 70\n",
      "Ripartion: 0.05 - trial: 71\n",
      "Ripartion: 0.05 - trial: 72\n",
      "Ripartion: 0.05 - trial: 73\n",
      "Ripartion: 0.05 - trial: 74\n",
      "Ripartion: 0.05 - trial: 75\n",
      "Ripartion: 0.05 - trial: 76\n",
      "Ripartion: 0.05 - trial: 77\n",
      "Ripartion: 0.05 - trial: 78\n",
      "Ripartion: 0.05 - trial: 79\n",
      "Ripartion: 0.05 - trial: 80\n",
      "Ripartion: 0.05 - trial: 81\n",
      "Ripartion: 0.05 - trial: 82\n",
      "Ripartion: 0.05 - trial: 83\n",
      "Ripartion: 0.05 - trial: 84\n",
      "Ripartion: 0.05 - trial: 85\n",
      "Ripartion: 0.05 - trial: 86\n",
      "Ripartion: 0.05 - trial: 87\n",
      "Ripartion: 0.05 - trial: 88\n",
      "Ripartion: 0.05 - trial: 89\n",
      "Ripartion: 0.05 - trial: 90\n",
      "Ripartion: 0.05 - trial: 91\n",
      "Ripartion: 0.05 - trial: 92\n",
      "Ripartion: 0.05 - trial: 93\n",
      "Ripartion: 0.05 - trial: 94\n",
      "Ripartion: 0.05 - trial: 95\n",
      "Ripartion: 0.05 - trial: 96\n",
      "Ripartion: 0.05 - trial: 97\n",
      "Ripartion: 0.05 - trial: 98\n",
      "Ripartion: 0.05 - trial: 99\n",
      "Param 2\n",
      "Ripartion: 0.1 - trial: 0\n",
      "Ripartion: 0.1 - trial: 1\n",
      "Ripartion: 0.1 - trial: 2\n",
      "Ripartion: 0.1 - trial: 3\n",
      "Ripartion: 0.1 - trial: 4\n",
      "Ripartion: 0.1 - trial: 5\n",
      "Ripartion: 0.1 - trial: 6\n",
      "Ripartion: 0.1 - trial: 7\n",
      "Ripartion: 0.1 - trial: 8\n",
      "Ripartion: 0.1 - trial: 9\n",
      "Ripartion: 0.1 - trial: 10\n",
      "Ripartion: 0.1 - trial: 11\n",
      "Ripartion: 0.1 - trial: 12\n",
      "Ripartion: 0.1 - trial: 13\n",
      "Ripartion: 0.1 - trial: 14\n",
      "Ripartion: 0.1 - trial: 15\n",
      "Ripartion: 0.1 - trial: 16\n",
      "Ripartion: 0.1 - trial: 17\n",
      "Ripartion: 0.1 - trial: 18\n",
      "Ripartion: 0.1 - trial: 19\n",
      "Ripartion: 0.1 - trial: 20\n",
      "Ripartion: 0.1 - trial: 21\n",
      "Ripartion: 0.1 - trial: 22\n",
      "Ripartion: 0.1 - trial: 23\n",
      "Ripartion: 0.1 - trial: 24\n",
      "Ripartion: 0.1 - trial: 25\n",
      "Ripartion: 0.1 - trial: 26\n",
      "Ripartion: 0.1 - trial: 27\n",
      "Ripartion: 0.1 - trial: 28\n",
      "Ripartion: 0.1 - trial: 29\n",
      "Ripartion: 0.1 - trial: 30\n",
      "Ripartion: 0.1 - trial: 31\n",
      "Ripartion: 0.1 - trial: 32\n",
      "Ripartion: 0.1 - trial: 33\n",
      "Ripartion: 0.1 - trial: 34\n",
      "Ripartion: 0.1 - trial: 35\n",
      "Ripartion: 0.1 - trial: 36\n",
      "Ripartion: 0.1 - trial: 37\n",
      "Ripartion: 0.1 - trial: 38\n",
      "Ripartion: 0.1 - trial: 39\n",
      "Ripartion: 0.1 - trial: 40\n",
      "Ripartion: 0.1 - trial: 41\n",
      "Ripartion: 0.1 - trial: 42\n",
      "Ripartion: 0.1 - trial: 43\n",
      "Ripartion: 0.1 - trial: 44\n",
      "Ripartion: 0.1 - trial: 45\n",
      "Ripartion: 0.1 - trial: 46\n",
      "Ripartion: 0.1 - trial: 47\n",
      "Ripartion: 0.1 - trial: 48\n",
      "Ripartion: 0.1 - trial: 49\n",
      "Ripartion: 0.1 - trial: 50\n",
      "Ripartion: 0.1 - trial: 51\n",
      "Ripartion: 0.1 - trial: 52\n",
      "Ripartion: 0.1 - trial: 53\n",
      "Ripartion: 0.1 - trial: 54\n",
      "Ripartion: 0.1 - trial: 55\n",
      "Ripartion: 0.1 - trial: 56\n",
      "Ripartion: 0.1 - trial: 57\n",
      "Ripartion: 0.1 - trial: 58\n",
      "Ripartion: 0.1 - trial: 59\n",
      "Ripartion: 0.1 - trial: 60\n",
      "Ripartion: 0.1 - trial: 61\n",
      "Ripartion: 0.1 - trial: 62\n",
      "Ripartion: 0.1 - trial: 63\n",
      "Ripartion: 0.1 - trial: 64\n",
      "Ripartion: 0.1 - trial: 65\n",
      "Ripartion: 0.1 - trial: 66\n",
      "Ripartion: 0.1 - trial: 67\n",
      "Ripartion: 0.1 - trial: 68\n",
      "Ripartion: 0.1 - trial: 69\n",
      "Ripartion: 0.1 - trial: 70\n",
      "Ripartion: 0.1 - trial: 71\n",
      "Ripartion: 0.1 - trial: 72\n",
      "Ripartion: 0.1 - trial: 73\n",
      "Ripartion: 0.1 - trial: 74\n",
      "Ripartion: 0.1 - trial: 75\n",
      "Ripartion: 0.1 - trial: 76\n",
      "Ripartion: 0.1 - trial: 77\n",
      "Ripartion: 0.1 - trial: 78\n",
      "Ripartion: 0.1 - trial: 79\n",
      "Ripartion: 0.1 - trial: 80\n",
      "Ripartion: 0.1 - trial: 81\n",
      "Ripartion: 0.1 - trial: 82\n",
      "Ripartion: 0.1 - trial: 83\n",
      "Ripartion: 0.1 - trial: 84\n",
      "Ripartion: 0.1 - trial: 85\n",
      "Ripartion: 0.1 - trial: 86\n",
      "Ripartion: 0.1 - trial: 87\n",
      "Ripartion: 0.1 - trial: 88\n",
      "Ripartion: 0.1 - trial: 89\n",
      "Ripartion: 0.1 - trial: 90\n",
      "Ripartion: 0.1 - trial: 91\n",
      "Ripartion: 0.1 - trial: 92\n",
      "Ripartion: 0.1 - trial: 93\n",
      "Ripartion: 0.1 - trial: 94\n",
      "Ripartion: 0.1 - trial: 95\n",
      "Ripartion: 0.1 - trial: 96\n",
      "Ripartion: 0.1 - trial: 97\n",
      "Ripartion: 0.1 - trial: 98\n",
      "Ripartion: 0.1 - trial: 99\n",
      "Param 2\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Lasso CD genetics\")\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "import sys, os\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" \n",
    "\n",
    "#number of trials\n",
    "trials = 100\n",
    "np.random.seed(42)\n",
    "seeds = np.random.randint(trials, size=trials)\n",
    "\n",
    "ripartisions = [i / 100 for i in range(5, 55, 5)]\n",
    "results = []  \n",
    "\n",
    "# create 5x2 subfigs\n",
    "fig = plt.figure(constrained_layout=True, figsize=(20, 25))\n",
    "fig.suptitle('LASSO regression test' + \"\\n\")\n",
    "subfigs = fig.subfigures(nrows=5, ncols=2).flatten()\n",
    "k = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''Param 1'''\n",
    "\n",
    "for ripartition in ripartisions:\n",
    "\n",
    "\n",
    "    MSE_param1 = []\n",
    "    best_MSE_1 = 100000000\n",
    "    best_data_1 = {\"Y_test\": None, \"Y_pred\": None, \"seed\": None,\"alpha\":None}\n",
    "\n",
    "\n",
    "    run_name = str(ripartition) + \" ripartition\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_param('ripartition', ripartition)\n",
    "    \n",
    "        i = 0\n",
    "        for i in range(trials):\n",
    "            print(\"Ripartion: \" + str(ripartition) + \" - trial: \" + str(i))\n",
    "            #Ripartition in training and test and\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:, 0], test_size=ripartition, random_state=seeds[i])\n",
    "            param_grid = {'alpha': Continuous(1/100000,0.01)}\n",
    "            lasso_reg_cd = Lasso(max_iter=5000, tol=1e-2)\n",
    "    \n",
    "                    \n",
    "            evolved_estimator = GASearchCV(estimator=lasso_reg_cd,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              param_grid=param_grid,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=False,\n",
    "                              population_size=10,\n",
    "                              generations=10)\n",
    "    \n",
    "            evolved_estimator.fit(X_train, Y_train)\n",
    "    \n",
    "            # Make predictions using the testing set\n",
    "            Y_pred_lasso_cd = evolved_estimator.predict(X_test)\n",
    "    \n",
    "            #save MSE of the first parameters\n",
    "            MSE_param1.append(mean_squared_error(Y_test, Y_pred_lasso_cd))\n",
    "    \n",
    "            #check if this is the best model in terms of MSE\n",
    "            if MSE_param1[-1] < best_MSE_1:\n",
    "                best_MSE_1 = MSE_param1[-1]\n",
    "                best_data_1[\"Y_test\"] = Y_test\n",
    "                best_data_1[\"Y_pred\"] = Y_pred_lasso_cd\n",
    "                best_data_1[\"alpha\"] = float(evolved_estimator.best_params_[\"alpha\"])\n",
    "                best_data_1[\"seed\"] = seeds[i]\n",
    "                \n",
    "        mlflow.log_metric(\"Best_MSE1\", best_MSE_1)\n",
    "        mlflow.log_metric(\"Mean_MSE1\", np.mean(MSE_param1))\n",
    "        mlflow.log_metric(\"Var_MSE1\", np.var(MSE_param1))\n",
    "        mlflow.log_metric(\"alpha1\", best_data_1[\"alpha\"])\n",
    "\n",
    "\n",
    "\n",
    "        MSE_param2 = []\n",
    "        best_MSE_2 = 100000000\n",
    "        best_data_2 = {\"Y_test\": None, \"Y_pred\": None, \"seed\": None, \"alpha\":None}\n",
    "        i = 0\n",
    "        for i in range(trials):\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:, 1], test_size=ripartition, random_state=seeds[i])\n",
    "            param_grid = {'alpha': Continuous(1/100000,0.01)}\n",
    "            lasso_reg_cd = Lasso(max_iter=5000, tol=1e-2)\n",
    "    \n",
    "                    \n",
    "            evolved_estimator = GASearchCV(estimator=lasso_reg_cd,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              param_grid=param_grid,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=False,\n",
    "                              population_size=10,\n",
    "                              generations=10)\n",
    "    \n",
    "            evolved_estimator.fit(X_train, Y_train)\n",
    "    \n",
    "            # Make predictions using the testing set\n",
    "            Y_pred_lasso_cd = evolved_estimator.predict(X_test)\n",
    "    \n",
    "            #save MSE of the second parameters\n",
    "            MSE_param2.append(mean_squared_error(Y_test, Y_pred_lasso_cd))\n",
    "    \n",
    "            #check if this is the best model in terms of MSE\n",
    "            if MSE_param2[-1] < best_MSE_2:\n",
    "                best_MSE_2 = MSE_param2[-1]\n",
    "                best_data_2[\"Y_test\"] = Y_test\n",
    "                best_data_2[\"Y_pred\"] = Y_pred_lasso_cd\n",
    "                best_data_2[\"alpha\"] = float(evolved_estimator.best_params_[\"alpha\"])\n",
    "                best_data_2[\"seed\"] = seeds[i]\n",
    "\n",
    "            \n",
    "       \n",
    "        mlflow.log_metric(\"Best_MSE2\", best_MSE_2)\n",
    "        mlflow.log_metric(\"Mean_MSE2\", np.mean(MSE_param2))\n",
    "        mlflow.log_metric(\"Var_MSE2\", np.var(MSE_param2))\n",
    "        mlflow.log_metric(\"alpha2\", best_data_2[\"alpha\"])\n",
    "            \n",
    "    results.append([str(ripartition * 100), str(best_MSE_1), str(best_MSE_2),\n",
    "                    (np.mean(MSE_param1)), str(np.mean(MSE_param2)), str(np.var(MSE_param1)), str(np.var(MSE_param2)),\n",
    "                    str(best_data_1[\"alpha\"]), str(best_data_2[\"alpha\"]), best_data_1[\"seed\"],best_data_2[\"seed\"]])\n",
    "\n",
    "    \n",
    "    '''PLOT THE BEST MODELS'''\n",
    "    subfigs[k].suptitle(\n",
    "        \"Lasso Regression with Coordinate Descent\" + \"\\n\" + \"Best MSE results\" + \"\\n\" + f\"Test size(%): {ripartition * 100}\")\n",
    "    # create 1x2 subplots per subfig\n",
    "    axs = subfigs[k].subplots(nrows=1, ncols=2)\n",
    "    axs[0].scatter(best_data_1[\"Y_test\"], best_data_1[\"Y_pred\"], c='blue', label='Actual vs Predicted')\n",
    "    axs[0].plot([min(best_data_1[\"Y_test\"]), max(best_data_1[\"Y_test\"])],\n",
    "                [min(best_data_1[\"Y_test\"]), max(best_data_1[\"Y_test\"])], '--', c='red', label='Perfect Prediction')\n",
    "    axs[0].legend()\n",
    "    axs[0].set_xlabel(\"Actual values\")\n",
    "    axs[0].set_ylabel(\"Predicted value\")\n",
    "    axs[0].set_title(\n",
    "        \"Parameter 1\" + \"\\n\" + \"MSE: \" + str(min(MSE_param1)) + \"\\n\" + \" alpha= \" + str(best_data_1[\"alpha\"]))\n",
    "\n",
    "    axs[1].scatter(best_data_2[\"Y_test\"], best_data_2[\"Y_pred\"], c='blue', label='Actual vs Predicted')\n",
    "    axs[1].plot([min(best_data_2[\"Y_test\"]), max(best_data_2[\"Y_test\"])],\n",
    "                [min(best_data_2[\"Y_test\"]), max(best_data_2[\"Y_test\"])], '--', c='red', label='Perfect Prediction')\n",
    "    axs[1].legend()\n",
    "    axs[1].set_xlabel(\"Actual values\")\n",
    "    axs[1].set_ylabel(\"Predicted value\")\n",
    "    axs[1].set_title(\n",
    "        \"Parameter 2\" + \"\\n\" + \"MSE: \" + str(min(MSE_param2)) + \"\\n\" + \" alpha= \" + str(best_data_2[\"alpha\"]))\n",
    "    k += 1\n",
    "\n",
    "\n",
    "'''SHOW RESULTS'''\n",
    "headers = [\"Test size(%)\", \"Best(MSE1)\", \"Best(MSE2)\", \"Mean(MSE1)\", \"Mean(MSE2)\", \"Var(MSE1)\", \"Var(MSE2)\",\n",
    "           \"alpha1\",\"alpha2\",\"Seed1\",\"Seed2\"]\n",
    "\n",
    "print(tabulate(results, headers, tablefmt=\"double_outline\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qL1pOKy3siP5"
   },
   "source": [
    "**LASSO with SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4q0s6y-6shme"
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Lasso SGD genetics\")\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" \n",
    "#number of trials\n",
    "trials = 100\n",
    "np.random.seed(42)\n",
    "seeds = np.random.randint(trials, size=trials)\n",
    "\n",
    "ripartisions = [i/100 for i in range(5,55,5)]\n",
    "results = [] \n",
    "\n",
    "\n",
    "print(\"Param 1\")\n",
    "for ripartition in ripartisions:\n",
    "\n",
    "    '''PARAM 1'''\n",
    "\n",
    "    MSE_param1 = []\n",
    "    best_MSE_1 = 100000000\n",
    "    best_data_1 = {\"Y_test\":None, \"Y_pred\":None,\"alpha\":None,\"seed\":None}\n",
    "\n",
    "    \n",
    "\n",
    "    run_name = str(ripartition) + \" ripartition\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_param('ripartition', ripartition)\n",
    "\n",
    "        i = 0\n",
    "        for i in range(trials):\n",
    "            #Ripartition in training and test and\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:,0], test_size=ripartition, random_state=seeds[i])\n",
    "            param_grid = {'alpha': Continuous(1/100000,0.01)}\n",
    "            lasso_reg_sgd = SGDRegressor(max_iter=5000, tol=1e-5, penalty=\"l1\", eta0=0.01,\n",
    "                                                n_iter_no_change=10, random_state=42)\n",
    "    \n",
    "            evolved_estimator = GASearchCV(estimator=lasso_reg_sgd,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              param_grid=param_grid,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=False,\n",
    "                              population_size=10,\n",
    "                              generations=10)\n",
    "    \n",
    "            #grid search will contain the best model\n",
    "            evolved_estimator.fit(X_train, Y_train)\n",
    "    \n",
    "            # Make predictions using the testing set\n",
    "            Y_pred_lasso_sgd =  evolved_estimator.predict(X_test)\n",
    "    \n",
    "            #save MSE of the first parameters\n",
    "            MSE_param1.append(mean_squared_error(Y_test, Y_pred_lasso_sgd))\n",
    "    \n",
    "            #check if this is the best model in terms of MSE\n",
    "            if MSE_param1[-1] < best_MSE_1:\n",
    "                best_MSE_1 = MSE_param1[-1]\n",
    "                best_data_1[\"Y_test\"] = Y_test\n",
    "                best_data_1[\"Y_pred\"] = Y_pred_lasso_sgd\n",
    "                best_data_1[\"alpha\"] =  float(evolved_estimator.best_params_[\"alpha\"])\n",
    "                best_data_1[\"seed\"] = seeds[i]\n",
    "        \n",
    "        mlflow.log_metric(\"Best_MSE1\", best_MSE_1)\n",
    "        mlflow.log_metric(\"Mean_MSE1\", np.mean(MSE_param1))\n",
    "        mlflow.log_metric(\"Var_MSE1\", np.var(MSE_param1))\n",
    "        mlflow.log_metric(\"alpha1\", best_data_1[\"alpha\"])\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Param 2\")    \n",
    "        '''PARAM 2'''\n",
    "        MSE_param2 = []\n",
    "\n",
    "        best_MSE_2 = 100000000\n",
    "        best_data_2 = {\"Y_test\":None, \"Y_pred\":None,\"alpha\":None,\"seed\":None}\n",
    "        i = 0\n",
    "        for i in range(trials):\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:,1], test_size=ripartition, random_state=seeds[i])\n",
    "            param_grid = {'alpha': Continuous(1/100000,0.01)}\n",
    "            lasso_reg_sgd = SGDRegressor(max_iter=5000, tol=1e-5, penalty=\"l1\", eta0=0.01,\n",
    "                                                n_iter_no_change=10, random_state=42)\n",
    "    \n",
    "            evolved_estimator = GASearchCV(estimator=lasso_reg_sgd,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              param_grid=param_grid,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=False,\n",
    "                              population_size=10,\n",
    "                              generations=10)\n",
    "    \n",
    "            #grid search will contain the best model\n",
    "            evolved_estimator.fit(X_train, Y_train)\n",
    "    \n",
    "            # Make predictions using the testing set\n",
    "            Y_pred_lasso_sgd =  evolved_estimator.predict(X_test)\n",
    "    \n",
    "            # Make predictions using the testing set\n",
    "            Y_pred_lasso_sgd = grid_search.predict(X_test)\n",
    "    \n",
    "            #save MSE of the second parameters\n",
    "            MSE_param2.append(mean_squared_error(Y_test, Y_pred_lasso_sgd))\n",
    "    \n",
    "            #check if this is the best model in terms of MSE\n",
    "            if MSE_param2[-1] < best_MSE_2:\n",
    "                best_MSE_2 = MSE_param2[-1]\n",
    "                best_data_2[\"Y_test\"] = Y_test\n",
    "                best_data_2[\"Y_pred\"] = Y_pred_lasso_sgd\n",
    "                best_data_2[\"alpha\"] =  float(evolved_estimator.best_params_[\"alpha\"])\n",
    "                best_data_2[\"seed\"] = seeds[i]\n",
    "\n",
    "        mlflow.log_metric(\"Best_MSE2\", best_MSE_2)\n",
    "        mlflow.log_metric(\"Mean_MSE2\", np.mean(MSE_param2))\n",
    "        mlflow.log_metric(\"Var_MSE2\", np.var(MSE_param2))\n",
    "        mlflow.log_metric(\"alpha2\", best_data_2[\"alpha\"])\n",
    "        \n",
    "\n",
    "    results.append([str(ripartition * 100), str(best_MSE_1), str(best_MSE_2),\n",
    "                    (np.mean(MSE_param1)), str(np.mean(MSE_param2)), str(np.var(MSE_param1)), str(np.var(MSE_param2)),\n",
    "                    str(best_data_1[\"alpha\"]), str(best_data_2[\"alpha\"]), best_data_1[\"seed\"],best_data_2[\"seed\"]])\n",
    "\n",
    "    \n",
    "    '''PLOT THE BEST MODELS'''\n",
    "    subfigs[k].suptitle(\n",
    "        \"Lasso Regression with SGD\" + \"\\n\" + \"Best MSE results\" + \"\\n\" + f\"Test size(%): {ripartition * 100}\")\n",
    "    # create 1x2 subplots per subfig\n",
    "    axs = subfigs[k].subplots(nrows=1, ncols=2)\n",
    "    axs[0].scatter(best_data_1[\"Y_test\"], best_data_1[\"Y_pred\"], c='blue', label='Actual vs Predicted')\n",
    "    axs[0].plot([min(best_data_1[\"Y_test\"]), max(best_data_1[\"Y_test\"])],\n",
    "                [min(best_data_1[\"Y_test\"]), max(best_data_1[\"Y_test\"])], '--', c='red', label='Perfect Prediction')\n",
    "    axs[0].legend()\n",
    "    axs[0].set_xlabel(\"Actual values\")\n",
    "    axs[0].set_ylabel(\"Predicted value\")\n",
    "    axs[0].set_title(\n",
    "        \"Parameter 1\" + \"\\n\" + \"MSE: \" + str(min(MSE_param1)) + \"\\n\" + \" alpha= \" + str(best_data_1[\"alpha\"]))\n",
    "\n",
    "    axs[1].scatter(best_data_2[\"Y_test\"], best_data_2[\"Y_pred\"], c='blue', label='Actual vs Predicted')\n",
    "    axs[1].plot([min(best_data_2[\"Y_test\"]), max(best_data_2[\"Y_test\"])],\n",
    "                [min(best_data_2[\"Y_test\"]), max(best_data_2[\"Y_test\"])], '--', c='red', label='Perfect Prediction')\n",
    "    axs[1].legend()\n",
    "    axs[1].set_xlabel(\"Actual values\")\n",
    "    axs[1].set_ylabel(\"Predicted value\")\n",
    "    axs[1].set_title(\n",
    "        \"Parameter 2\" + \"\\n\" + \"MSE: \" + str(min(MSE_param2)) + \"\\n\" + \" alpha= \" + str(best_data_2[\"alpha\"]))\n",
    "    k += 1\n",
    "\n",
    "\n",
    "'''SHOW RESULTS'''\n",
    "headers = [\"Test size(%)\", \"Best(MSE1)\", \"Best(MSE2)\", \"Mean(MSE1)\", \"Mean(MSE2)\", \"Var(MSE1)\", \"Var(MSE2)\",\n",
    "           \"alpha1\",\"alpha2\",\"Seed1\",\"Seed2\"]\n",
    "\n",
    "print(tabulate(results, headers,  tablefmt=\"double_outline\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
