{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7232bf88-a6fc-4c4c-813c-594ae02aa9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "from itertools import product\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, PredictionErrorDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tabulate import tabulate\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "path = 'SAMPLE_DATA_SET.xlsx'\n",
    "\n",
    "# Read and load dataset\n",
    "df= pd.read_excel(path, sheet_name=[0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee6dcd7-ecc7-4cf3-86b6-0ff9f523e8d2",
   "metadata": {},
   "source": [
    "**INPUT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923d6473-8967-414a-ba8d-e40676cc18f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 444)\n"
     ]
    }
   ],
   "source": [
    "X =df.get(0)\n",
    "X = (X.iloc[:,1:]).values\n",
    "X = X.T\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538aee19-2ede-497d-b0d0-4fc63003872c",
   "metadata": {},
   "source": [
    "OUTPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506512c9-5449-4b74-a91b-0c2dc768030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 2)\n"
     ]
    }
   ],
   "source": [
    "Y =df.get(1)\n",
    "Y = (Y.iloc[:,:]).values\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c143f-ebb5-4858-87a1-172f85d019dc",
   "metadata": {},
   "source": [
    "LASSO with coordinate descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e72701b-c2a2-4c69-8ce4-652c9d6db6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/05 12:51:50 INFO mlflow.tracking.fluent: Experiment with name 'LASSO with CD' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 0\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 1\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 2\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 3\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 4\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 5\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 6\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 7\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 8\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 9\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 10\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 11\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 12\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 13\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 14\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 15\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 16\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 17\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 18\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 19\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 20\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 21\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 22\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 23\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 24\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n",
      "trial: 25\n",
      "Ripartition: 0.05\n",
      "alpha: 1e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, Y[:,\u001b[38;5;241m0\u001b[39m], test_size\u001b[38;5;241m=\u001b[39mripartition, random_state\u001b[38;5;241m=\u001b[39mseeds[i])\n\u001b[1;32m     48\u001b[0m lasso_reg_cd \u001b[38;5;241m=\u001b[39m Lasso(alpha \u001b[38;5;241m=\u001b[39m alpha, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m \u001b[43mlasso_reg_cd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Make predictions using the testing set\u001b[39;00m\n\u001b[1;32m     53\u001b[0m Y_pred_lasso_cd \u001b[38;5;241m=\u001b[39m  lasso_reg_cd\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:1050\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_alphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis_Xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# from here on **params\u001b[39;49;00m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1074\u001b[0m coef_[k] \u001b[38;5;241m=\u001b[39m this_coef[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1075\u001b[0m dual_gaps_[k] \u001b[38;5;241m=\u001b[39m this_dual_gap[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:678\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    664\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    665\u001b[0m         coef_,\n\u001b[1;32m    666\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    675\u001b[0m         positive,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcd_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menet_coordinate_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    683\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n\u001b[1;32m    685\u001b[0m     )\n",
      "File \u001b[0;32msklearn/linear_model/_cd_fast.pyx:265\u001b[0m, in \u001b[0;36msklearn.linear_model._cd_fast.enet_coordinate_descent\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/getlimits.py:486\u001b[0m, in \u001b[0;36mfinfo.__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, dtype):\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finfo_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# most common path\u001b[39;00m\n\u001b[1;32m    487\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"LASSO with CD\")\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "name_experiment = 'LASSO with CD'\n",
    "\n",
    "#number of trials\n",
    "trials = 100\n",
    "np.random.seed(42)\n",
    "seeds = np.random.randint(trials, size=trials)\n",
    "\n",
    "ripartisions = [i/100 for i in range(5,55,5)]\n",
    "results = []  #[\"Ripartition\", \"Best_MSE1\", \"Best_MSE2\",\"MSE1_mean\",\"MSE2_mean\",\"MSE1_var\",\"MSE2_var\",\"alpha1\",\"alpha2\"]\n",
    "\n",
    "\n",
    "for ripartition in ripartisions:\n",
    "\n",
    "   '''PARAM 1'''\n",
    "\n",
    "   MSE_param1 = []\n",
    "\n",
    "   best_MSE_1 = 100000000\n",
    "   best_data_1 = {\"Y_test\":None, \"Y_pred\":None,\"alpha\":None}\n",
    "   MSE_param2 = []\n",
    "   best_MSE_2 = 100000000\n",
    "   best_data_2 = {\"Y_test\":None, \"Y_pred\":None,\"alpha\":None}\n",
    "   param_grid = [i/100000 for i in range(1,10001,1)]\n",
    "\n",
    "\n",
    "   i = 0\n",
    "   for alpha in param_grid:\n",
    "        with mlflow.start_run(run_name=name_experiment):\n",
    "           # Tell mlflow to log the following parameters for the experiments dashboard\n",
    "           mlflow.log_param('ripartition', ripartition)\n",
    "           mlflow.log_param('alpha', alpha)\n",
    "           for i in range(trials):\n",
    "               #Ripartition in training and test and\n",
    "               X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:,0], test_size=ripartition, random_state=seeds[i])\n",
    "               lasso_reg_cd = Lasso(alpha = alpha, max_iter=5000, tol=1e-2)\n",
    "        \n",
    "               lasso_reg_cd.fit(X_train, Y_train)\n",
    "        \n",
    "               # Make predictions using the testing set\n",
    "               Y_pred_lasso_cd =  lasso_reg_cd.predict(X_test)\n",
    "        \n",
    "               #save MSE of the first parameters\n",
    "               MSE_param1.append(mean_squared_error(Y_test, Y_pred_lasso_cd))\n",
    "        \n",
    "               #check if this is the best model in terms of MSE\n",
    "               if MSE_param1[-1] < best_MSE_1:\n",
    "                 best_MSE_1 = MSE_param1[-1]\n",
    "                 best_data_1[\"Y_test\"] = Y_test\n",
    "                 best_data_1[\"Y_pred\"] = Y_pred_lasso_cd\n",
    "                 best_data_1[\"alpha\"] = alpha\n",
    "\n",
    "\n",
    "\n",
    "               X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:,1], test_size=ripartition, random_state=seeds[i])\n",
    "               lasso_reg_cd = Lasso(alpha = alpha, max_iter=5000, tol=1e-2)\n",
    "        \n",
    "               lasso_reg_cd.fit(X_train, Y_train)\n",
    "        \n",
    "               # Make predictions using the testing set\n",
    "               Y_pred_lasso_cd =  lasso_reg_cd.predict(X_test)\n",
    "        \n",
    "               #save MSE of the second parameters\n",
    "               MSE_param2.append(mean_squared_error(Y_test, Y_pred_lasso_cd))\n",
    "        \n",
    "               #check if this is the best model in terms of MSE\n",
    "               if MSE_param2[-1] < best_MSE_2:\n",
    "                   best_MSE_2 = MSE_param2[-1]\n",
    "                   best_data_2[\"Y_test\"] = Y_test\n",
    "                   best_data_2[\"Y_pred\"] = Y_pred_lasso_cd\n",
    "                   best_data_2[\"alpha\"] =  alpha\n",
    "            \n",
    "               mlflow.log_metric(\"MSE 1\", MSE_param1[-1])\n",
    "               mlflow.log_metric(\"MSE 2\", MSE_param2[-1])\n",
    "               mlflow.log_metric(\"alpha\", alpha)\n",
    "\n",
    "   results.append([str(ripartition *100 ), str(best_MSE_1), str(best_MSE_2),\n",
    "   (np.mean(MSE_param1)),str(np.mean(MSE_param2)), str(np.var(MSE_param1)), str(np.var(MSE_param2)), str(best_data_1[\"alpha\"]), str(best_data_2[\"alpha\"])])\n",
    "\n",
    "    \n",
    "   \n",
    "   '''PLOT THE BEST MODELS'''\n",
    "   fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "   plt.subplots_adjust(wspace=0.3)\n",
    "   PredictionErrorDisplay.from_predictions(y_true=best_data_1[\"Y_test\"], y_pred=best_data_1[\"Y_pred\"], kind = \"actual_vs_predicted\", ax=axs[0])\n",
    "   axs[0].set_title(\"Parameter 1\"+\"\\n\"+ \"MSE: \" +  str(min(MSE_param1)) + \"\\n\" + \" alpha= \"+ str(best_data_1[\"alpha\"]))\n",
    "   disp2= PredictionErrorDisplay.from_predictions(y_true=best_data_2[\"Y_test\"], y_pred=best_data_2[\"Y_pred\"], kind = \"actual_vs_predicted\", ax=axs[1])\n",
    "   axs[1].set_title(\"Parameter 2\"+\"\\n\"+ \"MSE: \" +  str(min(MSE_param2))  + \"\\n\" + \" alpha= \"+ str(best_data_2[\"alpha\"]))\n",
    "   fig.suptitle(\"Lasso Regression with Coordinate Descent\"+\"\\n\"+ \"Best MSE results\" + \"\\n\"+ f\"Test size(%): {ripartition * 100}\")\n",
    "   plt.tight_layout()\n",
    "   plt.show()\n",
    "\n",
    "\n",
    "'''SHOW RESULTS'''\n",
    "headers = [\"Test size(%)\",\"Best(MSE1)\", \"Best(MSE2)\",\"Mean(MSE1)\", \"Mean(MSE2)\", \"Var(MSE1)\", \"Var(MSE2)\",\"alpha1\",\"alpha2\"]\n",
    "\n",
    "print(tabulate(results, headers,  tablefmt=\"double_outline\"))\n",
    "mlflow.end_run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8188b84-3765-4143-816c-76f8455548fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of experiments: 24\n",
      "Running experiment number  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: .git non è un repository Git (né lo è alcuna delle directory genitrici)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_xgboost_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(n_estimators\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m3\u001b[39m], \n\u001b[1;32m     31\u001b[0m                       max_depth\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     32\u001b[0m                       scale_pos_weight\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     33\u001b[0m                       learning_rate\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m---> 35\u001b[0m     clf \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_xgboost_pipeline\u001b[49m(data_train\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloan_risk\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     36\u001b[0m                                  data_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloan_risk\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     37\u001b[0m                                  parameters\u001b[38;5;241m=\u001b[39mparameters)\n\u001b[1;32m     40\u001b[0m     report_val \u001b[38;5;241m=\u001b[39m classification_report(data_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloan_risk\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     41\u001b[0m                                        clf\u001b[38;5;241m.\u001b[39mpredict(data_val\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloan_risk\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)), \n\u001b[1;32m     42\u001b[0m                                        output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m     report_test \u001b[38;5;241m=\u001b[39m classification_report(data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloan_risk\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     45\u001b[0m                                         clf\u001b[38;5;241m.\u001b[39mpredict(data_test\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloan_risk\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)), \n\u001b[1;32m     46\u001b[0m                                         output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_xgboost_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "max_depth = [3, 6]\n",
    "scale_pos_weight = [0.1, 1, 10]\n",
    "learning_rate = [0.01, 0.001]\n",
    "n_estimators = [100, 50]\n",
    "\n",
    "name_experiment = 'Primissima grid-search'\n",
    "\n",
    "parameters = product(max_depth, scale_pos_weight, learning_rate, n_estimators)\n",
    "parameters_list = list(parameters)\n",
    "\n",
    "print('Number of experiments:', len(parameters_list))\n",
    "\n",
    "# Hyperparameter search\n",
    "results = []\n",
    "best_param = None\n",
    "best_f1 = 0.0\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for i, param in enumerate(parameters_list):\n",
    "    print('Running experiment number ', i)\n",
    "    with mlflow.start_run(run_name=name_experiment):\n",
    "        # Tell mlflow to log the following parameters for the experiments dashboard\n",
    "        mlflow.log_param('max_depth', param[0])\n",
    "        mlflow.log_param('scale_pos_weight', param[1])\n",
    "        mlflow.log_param('learning_rate', param[2])\n",
    "        mlflow.log_param('n_estimators', param[3])\n",
    "        mlflow.log_param('version', os.system('git describe --all --long'))\n",
    "\n",
    "        try:\n",
    "            parameters = dict(n_estimators=param[3], \n",
    "                              max_depth=param[0], \n",
    "                              scale_pos_weight=param[1],\n",
    "                              learning_rate=param[2])\n",
    "\n",
    "            clf = train_xgboost_pipeline(data_train.drop(['loan_risk'],axis=1),\n",
    "                                         data_train['loan_risk'], \n",
    "                                         parameters=parameters)\n",
    "            \n",
    "            \n",
    "            report_val = classification_report(data_val['loan_risk'],\n",
    "                                               clf.predict(data_val.drop(['loan_risk'],axis=1)), \n",
    "                                               output_dict=True)\n",
    "\n",
    "            report_test = classification_report(data_test['loan_risk'],\n",
    "                                                clf.predict(data_test.drop(['loan_risk'],axis=1)), \n",
    "                                                output_dict=True)\n",
    "\n",
    "            # Tell mlflow to log the following metrics\n",
    "            mlflow.log_metric(\"recall\", report_val['Charged off']['recall'])            \n",
    "            mlflow.log_metric(\"precision\", report_val['Charged off']['precision'])\n",
    "            mlflow.log_metric(\"F1\", report_val['Charged off']['f1-score'])\n",
    "\n",
    "            # Store this artifact for each run\n",
    "            json.dump(report_test, open(\"metrics.json\", \"w\"))\n",
    "            mlflow.log_artifact('./metrics.json')\n",
    "\n",
    "            # save the best experiment yet (in terms of precision)\n",
    "            if report_val['Charged off']['f1-score'] > best_f1:\n",
    "                best_param = parameters\n",
    "                best_f1 = report_val['Charged off']['f1-score']\n",
    "            \n",
    "                                            \n",
    "            results.append([param, report_val['Charged off']['f1-score']])\n",
    "\n",
    "        except ValueError:\n",
    "            print('bad parameter combination:', param)\n",
    "            continue\n",
    "\n",
    "mlflow.end_run()\n",
    "print('Best F1 was:', best_f1)\n",
    "print('Using the following parameters')\n",
    "print(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd712860-9316-42c7-ba34-92eff9e753dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
