{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2963d459-d6bd-4e0e-92d8-89b5003b86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.dsl import component\n",
    "from typing import Optional\n",
    "\n",
    "@component(\n",
    "    base_image='python:3.11.10',\n",
    "    packages_to_install=['minio', 'pandas', 'openpyxl','numpy==1.24.4']\n",
    ")\n",
    "def get_X() -> int:\n",
    "    import pandas as pd\n",
    "    from minio import Minio\n",
    "\n",
    "    # Initialize MinIO client\n",
    "    client = Minio(\"10.111.218.179:9000\", access_key=\"minio\", secret_key=\"minio123\", secure=False)\n",
    "\n",
    "    # Download the CSV file\n",
    "    response = client.fget_object(\"mlpipeline\", \"LEAF_LEVEL_DATASET_Yufeng_Ge.xlsx\",\"file.xlsx\")\n",
    "   \n",
    "    # Read and load dataset\n",
    "    df= pd.read_excel(\"file.xlsx\", sheet_name=[0, 1])\n",
    "\n",
    "    X =df.get(0)\n",
    "    X = (X.iloc[:,14:])\n",
    "    X.to_csv(\"input_X.csv\", index=False)\n",
    "\n",
    "    client.fput_object(\"mlpipeline\", \"input_X.csv\", \"input_X.csv\")\n",
    "    return 0\n",
    "\n",
    "@component(\n",
    "    base_image='python:3.11.10',\n",
    "    packages_to_install=['minio', 'pandas', 'openpyxl','numpy==1.24.4']\n",
    ")\n",
    "def get_Y() -> int:\n",
    "    import pandas as pd\n",
    "    from minio import Minio\n",
    "    # Initialize MinIO client\n",
    "    client = Minio(\"10.111.218.179:9000\", access_key=\"minio\", secret_key=\"minio123\", secure=False)\n",
    "   \n",
    "    # Download the CSV file\n",
    "    response = client.fget_object(\"mlpipeline\", \"LEAF_LEVEL_DATASET_Yufeng_Ge.xlsx\",\"file.xlsx\")\n",
    "   \n",
    "\n",
    "    # Read and load dataset\n",
    "    df= pd.read_excel(\"file.xlsx\", sheet_name=[0, 1])\n",
    "    Y =df.get(0)\n",
    "    Y = (Y.iloc[:,7])\n",
    "    Y.to_csv(\"input_Y.csv\", index=False)\n",
    "\n",
    "    client.fput_object(\"mlpipeline\", \"input_Y.csv\", \"input_Y.csv\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def NRMSEPiqr(observed_values, predicted_values):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@component(\n",
    "    base_image='python:3.11.10',\n",
    "    packages_to_install=['scikit-learn', 'pandas','minio','openpyxl','numpy==1.24.4']\n",
    ")\n",
    "def train_model(X: int, Y:int) -> str:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import Ridge\n",
    "    import pandas as pd\n",
    "    from minio import Minio\n",
    "    from joblib import dump\n",
    "    client = Minio(\"10.111.218.179:9000\", access_key=\"minio\", secret_key=\"minio123\", secure=False)\n",
    "   \n",
    "    # Download the CSV files\n",
    "    response = client.fget_object(\"mlpipeline\",\"input_X.csv\", \"input_X.csv\")\n",
    "    response = client.fget_object(\"mlpipeline\",\"input_Y.csv\", \"input_Y.csv\")\n",
    "\n",
    "    X = df= pd.read_csv(\"input_X.csv\")\n",
    "    Y = df= pd.read_csv(\"input_Y.csv\")\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=21)\n",
    "    alpha = 0.26160739\n",
    "    ridge_reg_pipeline = make_pipeline(StandardScaler(),Ridge(alpha=alpha))\n",
    "\n",
    "    ridge_reg_pipeline.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make predictions using the testing set\n",
    "    Y_pred_ridge_cl =  ridge_reg_pipeline.predict(X_test)\n",
    "    dump(ridge_reg_pipeline, 'model.joblib')\n",
    "    client.fput_object(\"mlpipeline\", 'models/leafRecognize/1/model.joblib', 'model.joblib')\n",
    "    cv_scores = cross_validate(best_model, X_train, Y_train, cv=sturges, scoring=NRMSEPiqrscorer,n_jobs=-1)   \n",
    "\n",
    "    # Calculate RMSEP\n",
    "    rmsep = np.sqrt(np.mean((Y_test - Y_pred_ridge_cl) ** 2))\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "    Q1 = np.percentile(Y_test, 25)\n",
    "    Q3 = np.percentile(Y_test, 75)\n",
    "\n",
    "    # Calculate IQR\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    return rmsep/IQR\n",
    "\n",
    "    return str(NRMSEPiqr(Y_test, Y_pred_ridge_cl))\n",
    "\n",
    "@component(\n",
    "    base_image='python:3.11.10',\n",
    "    packages_to_install=[\n",
    "        'kserve',\n",
    "        'numpy==1.24.4',\n",
    "        'pandas'\n",
    "    ]\n",
    ")\n",
    "def create_inference_service(\n",
    "    model_uri: str,\n",
    "    model_name: str,\n",
    "    namespace: str = \"kubeflow-user-example-com\",\n",
    "    min_replicas: Optional[int] = None,\n",
    "    max_replicas: Optional[int] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Deploy a model using KServe.\n",
    "\n",
    "    Args:\n",
    "        model_uri (str): URI of the model to deploy.\n",
    "        model_name (str): Name for the deployed model.\n",
    "        namespace (str): Kubernetes namespace for deployment.\n",
    "        min_replicas (int, optional): Minimum number of replicas.\n",
    "        max_replicas (int, optional): Maximum number of replicas.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If deployment fails.\n",
    "    \"\"\"\n",
    "    import logging\n",
    "    from kubernetes import client, config\n",
    "    from kserve import (\n",
    "        KServeClient,\n",
    "        constants,\n",
    "        V1beta1InferenceService,\n",
    "        V1beta1InferenceServiceSpec,\n",
    "        V1beta1PredictorSpec,\n",
    "        V1beta1SKLearnSpec\n",
    "    )\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    try:\n",
    "        config.load_incluster_config()\n",
    "        kserve_client = KServeClient()\n",
    "        \n",
    "        predictor_spec = V1beta1PredictorSpec(\n",
    "            min_replicas=min_replicas,\n",
    "            max_replicas=max_replicas,\n",
    "            service_account_name = \"sa-minio-kserve\",\n",
    "            #sklearn=(storage_uri=model_uri)\n",
    "            sklearn=V1beta1SKLearnSpec(storage_uri=model_uri, image=\"kserve/sklearnserver:latest\" )\n",
    "        )\n",
    "        '''\n",
    "        resource_requirements = client.V1ResourceRequirements(\n",
    "        requests={\"cpu\": \"300m\"},  # Richiesta minima di 500 milliCPU\n",
    "        limits={\"cpu\": \"1\"}        # Limite massimo di 1 CPU\n",
    "        )'''\n",
    "        inference_service = V1beta1InferenceService(\n",
    "            api_version=constants.KSERVE_GROUP + '/v1beta1',\n",
    "            kind=constants.KSERVE_KIND,\n",
    "            metadata=client.V1ObjectMeta(name=model_name, \n",
    "                                         namespace=namespace,\n",
    "                                         annotations={'sidecar.istio.io/inject':'false'}),\n",
    "            spec=V1beta1InferenceServiceSpec(predictor=predictor_spec)  # Impostazione delle risorse\n",
    "        )\n",
    "        \n",
    "        kserve_client.create(inference_service)\n",
    "        logger.info(f\"Model {model_name} deployed successfully in namespace {namespace}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to deploy model {model_name}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "    name='Ridge_MSE',\n",
    "    description='Inference Service Ridge'\n",
    ")\n",
    "def Ridge_MSE():\n",
    "    X = get_X().output\n",
    "    Y = get_Y().output\n",
    "    create_inference_service(\n",
    "     model_uri=\"s3://mlpipeline/models/leafRecognize/1/\",\n",
    "     model_name=train_model(X=X, Y=Y).output,\n",
    "     min_replicas=1,\n",
    "     max_replicas=3\n",
    "    )\n",
    "    \n",
    "#pipeline_file_path = 'Ridge_MSE.yaml' # extract it from your database\n",
    "from kfp.compiler import Compiler\n",
    "\n",
    "# Compile the pipeline\n",
    "pipeline_filename = 'Ridge_MSE.yaml'\n",
    "Compiler().compile(pipeline_func=Ridge_MSE, package_path=pipeline_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25731526-cbe0-4c61-bbc8-5f5cd643fbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
